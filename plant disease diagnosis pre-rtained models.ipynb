{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1EOaWroaUIWb6KcVrNc5-lDn_lUhUfLe-",
      "authorship_tag": "ABX9TyPMlJhUVxQlTXRwuqraFDtE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amr552/Deep-learning-computer-vision/blob/main/plant%20disease%20diagnosis%20pre-rtained%20models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Af3qkRuI9Xho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d2bbf5-3a62-4f48-fbb3-2d23e7876b1e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 3251 images belonging to 4 classes.\n",
            "Found 416 images belonging to 4 classes.\n",
            "\n",
            "🔧 Training ResNet50...\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.3574 - loss: 1.1696"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m881s\u001b[0m 9s/step - accuracy: 0.3576 - loss: 1.1692 - val_accuracy: 0.3630 - val_loss: 1.1683\n",
            "Epoch 2/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m651s\u001b[0m 6s/step - accuracy: 0.4139 - loss: 1.0912 - val_accuracy: 0.4904 - val_loss: 0.9992\n",
            "Epoch 3/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m598s\u001b[0m 6s/step - accuracy: 0.4507 - loss: 1.0191 - val_accuracy: 0.5601 - val_loss: 0.9620\n",
            "Epoch 4/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m604s\u001b[0m 6s/step - accuracy: 0.4798 - loss: 1.0161 - val_accuracy: 0.5192 - val_loss: 0.9673\n",
            "Epoch 5/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m607s\u001b[0m 6s/step - accuracy: 0.5165 - loss: 0.9691 - val_accuracy: 0.4255 - val_loss: 1.0465\n",
            "Epoch 6/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 6s/step - accuracy: 0.5387 - loss: 0.9602 - val_accuracy: 0.5048 - val_loss: 0.9816\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔧 Training ResNet101...\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m171446536/171446536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1137s\u001b[0m 11s/step - accuracy: 0.3707 - loss: 1.1533 - val_accuracy: 0.4832 - val_loss: 0.9996\n",
            "Epoch 2/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1096s\u001b[0m 11s/step - accuracy: 0.4518 - loss: 1.0351 - val_accuracy: 0.5529 - val_loss: 0.9545\n",
            "Epoch 3/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1102s\u001b[0m 11s/step - accuracy: 0.4862 - loss: 1.0075 - val_accuracy: 0.5841 - val_loss: 0.9445\n",
            "Epoch 4/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1114s\u001b[0m 11s/step - accuracy: 0.5037 - loss: 0.9730 - val_accuracy: 0.5048 - val_loss: 0.9401\n",
            "Epoch 5/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1096s\u001b[0m 11s/step - accuracy: 0.5270 - loss: 0.9724 - val_accuracy: 0.4928 - val_loss: 0.9770\n",
            "Epoch 6/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1114s\u001b[0m 11s/step - accuracy: 0.5148 - loss: 0.9579 - val_accuracy: 0.4928 - val_loss: 0.9518\n",
            "Epoch 7/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1098s\u001b[0m 11s/step - accuracy: 0.5245 - loss: 0.9597 - val_accuracy: 0.5072 - val_loss: 0.9272\n",
            "Epoch 8/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1095s\u001b[0m 11s/step - accuracy: 0.5490 - loss: 0.9464 - val_accuracy: 0.5216 - val_loss: 0.9626\n",
            "Epoch 9/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1096s\u001b[0m 11s/step - accuracy: 0.5171 - loss: 0.9609 - val_accuracy: 0.5192 - val_loss: 0.9350\n",
            "Epoch 10/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1087s\u001b[0m 11s/step - accuracy: 0.5224 - loss: 0.9927 - val_accuracy: 0.6010 - val_loss: 0.9037\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔧 Training EfficientNetB0...\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 3s/step - accuracy: 0.3595 - loss: 1.1522 - val_accuracy: 0.3918 - val_loss: 1.0998\n",
            "Epoch 2/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 3s/step - accuracy: 0.3691 - loss: 1.1103 - val_accuracy: 0.3918 - val_loss: 1.1622\n",
            "Epoch 3/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 3s/step - accuracy: 0.3661 - loss: 1.1103 - val_accuracy: 0.3918 - val_loss: 1.1236\n",
            "Epoch 4/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 3s/step - accuracy: 0.3853 - loss: 1.1019 - val_accuracy: 0.3918 - val_loss: 1.0875\n",
            "Epoch 5/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 3s/step - accuracy: 0.3725 - loss: 1.1056 - val_accuracy: 0.3918 - val_loss: 1.0863\n",
            "Epoch 6/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 2s/step - accuracy: 0.3915 - loss: 1.0874 - val_accuracy: 0.3918 - val_loss: 1.0872\n",
            "Epoch 7/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 3s/step - accuracy: 0.4048 - loss: 1.0830 - val_accuracy: 0.3630 - val_loss: 1.0848\n",
            "Epoch 8/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 3s/step - accuracy: 0.3918 - loss: 1.0889 - val_accuracy: 0.3630 - val_loss: 1.0822\n",
            "Epoch 9/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 3s/step - accuracy: 0.3730 - loss: 1.0873 - val_accuracy: 0.3918 - val_loss: 1.0895\n",
            "Epoch 10/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 3s/step - accuracy: 0.3993 - loss: 1.0777 - val_accuracy: 0.3918 - val_loss: 1.0923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔧 Training EfficientNetB3...\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
            "\u001b[1m43941136/43941136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m542s\u001b[0m 5s/step - accuracy: 0.3357 - loss: 1.1646 - val_accuracy: 0.3918 - val_loss: 1.0996\n",
            "Epoch 2/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m555s\u001b[0m 5s/step - accuracy: 0.3841 - loss: 1.1080 - val_accuracy: 0.3918 - val_loss: 1.1062\n",
            "Epoch 3/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 5s/step - accuracy: 0.4028 - loss: 1.0895 - val_accuracy: 0.3918 - val_loss: 1.0970\n",
            "Epoch 4/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m540s\u001b[0m 5s/step - accuracy: 0.4139 - loss: 1.0850 - val_accuracy: 0.3918 - val_loss: 1.0823\n",
            "Epoch 5/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 5s/step - accuracy: 0.3728 - loss: 1.0952 - val_accuracy: 0.3918 - val_loss: 1.0846\n",
            "Epoch 6/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 5s/step - accuracy: 0.3858 - loss: 1.0879 - val_accuracy: 0.3918 - val_loss: 1.0851\n",
            "Epoch 7/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m533s\u001b[0m 5s/step - accuracy: 0.4138 - loss: 1.0719 - val_accuracy: 0.4591 - val_loss: 1.0865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔧 Training DenseNet121...\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 6s/step - accuracy: 0.7576 - loss: 0.6044 - val_accuracy: 0.9327 - val_loss: 0.1836\n",
            "Epoch 2/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 6s/step - accuracy: 0.9004 - loss: 0.2597 - val_accuracy: 0.9375 - val_loss: 0.1599\n",
            "Epoch 3/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m603s\u001b[0m 6s/step - accuracy: 0.9180 - loss: 0.2195 - val_accuracy: 0.9519 - val_loss: 0.1353\n",
            "Epoch 4/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 6s/step - accuracy: 0.9168 - loss: 0.2173 - val_accuracy: 0.9567 - val_loss: 0.1308\n",
            "Epoch 5/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 6s/step - accuracy: 0.9348 - loss: 0.1751 - val_accuracy: 0.9639 - val_loss: 0.1129\n",
            "Epoch 6/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m622s\u001b[0m 6s/step - accuracy: 0.9317 - loss: 0.1746 - val_accuracy: 0.9591 - val_loss: 0.1195\n",
            "Epoch 7/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m625s\u001b[0m 6s/step - accuracy: 0.9387 - loss: 0.1685 - val_accuracy: 0.9615 - val_loss: 0.1135\n",
            "Epoch 8/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m630s\u001b[0m 6s/step - accuracy: 0.9311 - loss: 0.1908 - val_accuracy: 0.9591 - val_loss: 0.1054\n",
            "Epoch 9/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m675s\u001b[0m 6s/step - accuracy: 0.9311 - loss: 0.1703 - val_accuracy: 0.9519 - val_loss: 0.1169\n",
            "Epoch 10/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 6s/step - accuracy: 0.9347 - loss: 0.1607 - val_accuracy: 0.9447 - val_loss: 0.1459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔧 Training MobileNetV2...\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.7719 - loss: 0.5553 - val_accuracy: 0.9255 - val_loss: 0.1857\n",
            "Epoch 2/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 2s/step - accuracy: 0.9262 - loss: 0.2155 - val_accuracy: 0.9279 - val_loss: 0.1916\n",
            "Epoch 3/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 2s/step - accuracy: 0.9248 - loss: 0.1963 - val_accuracy: 0.9399 - val_loss: 0.1760\n",
            "Epoch 4/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 2s/step - accuracy: 0.9339 - loss: 0.1770 - val_accuracy: 0.9351 - val_loss: 0.1708\n",
            "Epoch 5/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 2s/step - accuracy: 0.9525 - loss: 0.1463 - val_accuracy: 0.9303 - val_loss: 0.2105\n",
            "Epoch 6/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 2s/step - accuracy: 0.9552 - loss: 0.1221 - val_accuracy: 0.9375 - val_loss: 0.1908\n",
            "Epoch 7/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 2s/step - accuracy: 0.9482 - loss: 0.1344 - val_accuracy: 0.8726 - val_loss: 0.3570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔧 Training InceptionV3...\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 5s/step - accuracy: 0.6918 - loss: 0.7558 - val_accuracy: 0.8918 - val_loss: 0.2662\n",
            "Epoch 2/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 4s/step - accuracy: 0.8626 - loss: 0.3406 - val_accuracy: 0.8918 - val_loss: 0.2398\n",
            "Epoch 3/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 4s/step - accuracy: 0.9002 - loss: 0.2720 - val_accuracy: 0.9014 - val_loss: 0.2224\n",
            "Epoch 4/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 4s/step - accuracy: 0.9056 - loss: 0.2692 - val_accuracy: 0.9183 - val_loss: 0.2078\n",
            "Epoch 5/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 4s/step - accuracy: 0.9003 - loss: 0.2503 - val_accuracy: 0.8990 - val_loss: 0.2144\n",
            "Epoch 6/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 4s/step - accuracy: 0.8994 - loss: 0.2340 - val_accuracy: 0.8798 - val_loss: 0.2670\n",
            "Epoch 7/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 4s/step - accuracy: 0.9106 - loss: 0.2314 - val_accuracy: 0.8846 - val_loss: 0.2668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔧 Training VGG16...\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2004s\u001b[0m 20s/step - accuracy: 0.5024 - loss: 1.0350 - val_accuracy: 0.7404 - val_loss: 0.6733\n",
            "Epoch 2/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2032s\u001b[0m 20s/step - accuracy: 0.7134 - loss: 0.6813 - val_accuracy: 0.8317 - val_loss: 0.5297\n",
            "Epoch 3/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1990s\u001b[0m 20s/step - accuracy: 0.7638 - loss: 0.5740 - val_accuracy: 0.8005 - val_loss: 0.5546\n",
            "Epoch 4/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1990s\u001b[0m 20s/step - accuracy: 0.7806 - loss: 0.5446 - val_accuracy: 0.8173 - val_loss: 0.5055\n",
            "Epoch 5/10\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1986s\u001b[0m 19s/step - accuracy: 0.7893 - loss: 0.5388 - val_accuracy: 0.8606 - val_loss: 0.4215\n",
            "Epoch 6/10\n",
            "\u001b[1m 32/102\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:13\u001b[0m 17s/step - accuracy: 0.7733 - loss: 0.5579"
          ]
        }
      ],
      "source": [
        "# 🔁 Master Script: Run All Pretrained Models on Leaf Dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 🔗 Dataset Path\n",
        "train_path = '/content/drive/MyDrive/datasets/PLD_3_Classes_256/Training'\n",
        "val_path = '/content/drive/MyDrive/datasets/PLD_3_Classes_256/Validation'\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10  # You can increase for real experiments\n",
        "\n",
        "# 📂 Output folders\n",
        "MODEL_DIR = '/content/drive/MyDrive/Models'\n",
        "RESULT_DIR = '/content/drive/MyDrive/Results'\n",
        "\n",
        "# Create output directories if they don't exist\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "os.makedirs(RESULT_DIR, exist_ok=True)\n",
        "\n",
        "# Verify directory existence\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "    print(f\"Error: Model directory not found at {MODEL_DIR}\")\n",
        "if not os.path.exists(RESULT_DIR):\n",
        "    print(f\"Error: Results directory not found at {RESULT_DIR}\")\n",
        "\n",
        "\n",
        "# 🧪 Define the list of model constructors\n",
        "model_list = {\n",
        "    'ResNet50': tf.keras.applications.ResNet50,\n",
        "    'ResNet101': tf.keras.applications.ResNet101,\n",
        "    'EfficientNetB0': tf.keras.applications.EfficientNetB0,\n",
        "    'EfficientNetB3': tf.keras.applications.EfficientNetB3,\n",
        "    'DenseNet121': tf.keras.applications.DenseNet121,\n",
        "    'MobileNetV2': tf.keras.applications.MobileNetV2,\n",
        "    'InceptionV3': tf.keras.applications.InceptionV3,\n",
        "    'VGG16': tf.keras.applications.VGG16\n",
        "}\n",
        "\n",
        "# 🧼 Data generator\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_gen = datagen.flow_from_directory(train_path, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical')\n",
        "val_gen = datagen.flow_from_directory(val_path, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical')\n",
        "num_classes = train_gen.num_classes\n",
        "\n",
        "# Define Early Stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "for name, constructor in model_list.items():\n",
        "    print(f'\\n🔧 Training {name}...\\n')\n",
        "\n",
        "    # 📌 Load base model\n",
        "    base = constructor(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base.trainable = False\n",
        "\n",
        "    x = base.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base.input, outputs=output)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # 🏋️ Train\n",
        "    history = model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS, verbose=1, callbacks=[early_stopping])\n",
        "\n",
        "    # 💾 Save model\n",
        "    model.save(f'{MODEL_DIR}/model_{name}.h5')\n",
        "\n",
        "    # 📊 Plot\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['accuracy'], label='train')\n",
        "    plt.plot(history.history['val_accuracy'], label='val')\n",
        "    plt.title(f'{name} Accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['loss'], label='train')\n",
        "    plt.plot(history.history['val_loss'], label='val')\n",
        "    plt.title(f'{name} Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig(f'{RESULT_DIR}/{name}_results.png')\n",
        "    plt.close()"
      ]
    }
  ]
}